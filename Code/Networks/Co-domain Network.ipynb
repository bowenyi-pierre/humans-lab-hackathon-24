{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f8647b7-f1a3-422a-b730-a1b3552267d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import plotly.graph_objects as go \n",
    "import ast\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a3f536b-cfc7-45f9-a0e4-c62de2e86985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract\n",
    "\n",
    "def extract_base_domain(url):\n",
    "    extracted = tldextract.extract(url)\n",
    "    return f\"{extracted.domain}.{extracted.suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7d324c6-8efd-41f7-88d5-323dd731ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = pd.read_csv(\"en_combined.csv\")\n",
    "es_data = pd.read_csv(\"es_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc5e16f9-c5ac-42de-a51c-966861f4c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_format(field):\n",
    "    return ast.literal_eval(field)\n",
    "\n",
    "en_data['hashtags'] = en_data['hashtags'].apply(convert_format)\n",
    "en_data['links'] = en_data['links'].apply(convert_format)\n",
    "en_data['mentionedUsers'] = en_data['mentionedUsers'].apply(convert_format)\n",
    "\n",
    "es_data['hashtags'] = es_data['hashtags'].apply(convert_format)\n",
    "es_data['links'] = es_data['links'].apply(convert_format)\n",
    "es_data['mentionedUsers'] = es_data['mentionedUsers'].apply(convert_format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b58f92-4b1b-4b4c-ab5e-e6b8421d006a",
   "metadata": {},
   "source": [
    "#### 1. Network construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49221b1d-a232-4c4e-924b-d2004c05f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overly general domains to exclude\n",
    "en_exclude_domains = [\"youtu.be\", \"x.com\", \"youtube.com\", \"dlvr.it\", \"trib.al\", \"ift.tt\", \"tiktok.com\", \"bit.ly\", \"yahoo.com\"]\n",
    "es_exclude_domains = [\"dlvr.it\", \"youtu.be\", \"youtube.com\", \"x.com\", \"bit.ly\", \"buff.ly\", \"ift.tt\", \"ow.ly\", \"tinyurl.com\", \"short.gy\", \"trib.al\", \"acortar.link\", \"uni.vi\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f156df-484e-4ba5-9cb0-2c5709ff2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_urls(dataframe, exclude_domains):\n",
    "    # Extract user-URL mappings\n",
    "    user_url_map = [\n",
    "        (user, extract_base_domain(url['expanded_url'])) \n",
    "        for user, urls in zip(dataframe['id_str'], dataframe['links'])\n",
    "        if isinstance(urls, list) \n",
    "        for url in urls \n",
    "        if (\n",
    "            isinstance(url, dict) and \n",
    "            'expanded_url' in url and \n",
    "            len(url['expanded_url']) != 0 and \n",
    "            extract_base_domain(url['expanded_url']) not in exclude_domains\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Create a DataFrame for user-URL pairs\n",
    "    user_url_df = pd.DataFrame(user_url_map, columns=[\"user\", \"url\"])\n",
    "    \n",
    "    # Count number of valid URLs per user\n",
    "    user_url_counts = user_url_df.groupby('user')['url'].nunique()\n",
    "    users_with_min_links = user_url_counts[user_url_counts >= 3].index\n",
    "\n",
    "    # Filter DataFrame to include only users with >= 3 URLs\n",
    "    user_url_df = user_url_df[user_url_df['user'].isin(users_with_min_links)]\n",
    "    unique_users = user_url_df['user'].nunique()\n",
    "    print(f\"Unique users sharing >= 3 unique URLs: {unique_users}\")\n",
    "    \n",
    "    return user_url_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6950b09-398f-4209-88a0-bec426a066e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_full_co_domain_network(dataframe, min_df=3, threshold=0.6, lang='en'):\n",
    "    # Extract and preprocess URLs\n",
    "    if lang == 'en':\n",
    "        user_url_df = preprocess_urls(dataframe, en_exclude_domains)\n",
    "    else:\n",
    "        user_url_df = preprocess_urls(dataframe, es_exclude_domains)\n",
    "\n",
    "    # Pivot the user-URL DataFrame to create a user-URL matrix\n",
    "    user_url_matrix = user_url_df.pivot_table(index=\"user\", columns=\"url\", aggfunc=len, fill_value=0)\n",
    "\n",
    "    # Calculate URL frequencies (column sums)\n",
    "    url_frequencies = user_url_matrix.sum(axis=0)\n",
    "\n",
    "    # Filter URLs based on min_df and max_df\n",
    "    valid_urls = url_frequencies[(url_frequencies >= min_df)].index\n",
    "    filtered_user_url_matrix = user_url_matrix[valid_urls]\n",
    "\n",
    "    # Convert to sparse matrix\n",
    "    user_url_sparse_matrix = csr_matrix(filtered_user_url_matrix.values)\n",
    "\n",
    "    # Apply TF-IDF transformation\n",
    "    tfidf_transformer = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True)\n",
    "    tfidf_matrix = tfidf_transformer.fit_transform(user_url_sparse_matrix)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    # Build user-user graph\n",
    "    user_ids = filtered_user_url_matrix.index\n",
    "    G = nx.Graph()\n",
    "    for i, user1 in enumerate(user_ids):\n",
    "        for j, user2 in enumerate(user_ids):\n",
    "            if i != j and similarity_matrix[i, j] > threshold:\n",
    "                G.add_edge(user1, user2, weight=similarity_matrix[i, j])\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e62346e-032a-4bdd-b6e4-fc8bb79fd9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_co_url_graph = construct_full_co_domain_network(en_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a80ca2-63e2-4621-905d-b0bd540b8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_co_url_graph.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bfc19b-25e0-4a5c-9c01-bf08ff56cd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_gexf(en_co_url_graph, \"co_url_network.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3424c-c23c-4749-8b44-3614f413d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_co_url_graph = construct_full_co_domain_network(es_data, lang='es')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e7637-5106-4778-af3a-2c905731808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_co_url_graph.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a8fd86-1372-456f-80a2-481bd71b4648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.write_gexf(es_co_url_graph, \"es_co_domain_network_new.gexf\")\n",
    "# nx.write_gexf(en_co_url_graph, \"en_co_domain_network_new.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1d03c-8031-4b00-a2aa-90e167002748",
   "metadata": {},
   "source": [
    "### 2. Cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6e3db1-2d02-44c6-80fc-b14f288b9abe",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2054f9b6-13e1-4443-b27a-d4ccb89f61b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_clusters = pd.read_csv(\"en_co_domain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b427350-d1f5-44f0-a064-8802dc917a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_clusters_64 = en_clusters[en_clusters['modularity_class']==64]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60288ad4-2613-4198-b01e-4e1102e74c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_clusters_64 = en_clusters_64.sort_values(by='eigencentrality', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc210df4-8279-453f-9a22-6f3b350e342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_top_domains(df, lang, data, exclude_domains):\n",
    "    \"\"\"\n",
    "    Prints the 20 most common domains in a cluster of nodes.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame representing the cluster, containing user IDs in the 'Id' column.\n",
    "    - lang: Language ('en' or 'es') for processing.\n",
    "    - data: DataFrame containing the raw tweet data for the respective language.\n",
    "    - exclude_domains: List of domains to exclude from counting.\n",
    "    \"\"\"\n",
    "    domains = []\n",
    "\n",
    "    # Iterate over each user in the cluster\n",
    "    for i, r in df.iterrows():\n",
    "        user = r['Id'] \n",
    "        user_data = data[data['id_str'] == user] \n",
    "        \n",
    "        for _, row in user_data.iterrows():\n",
    "            urls = row['links']\n",
    "            if isinstance(urls, list):\n",
    "                for url in urls:\n",
    "                    if (\n",
    "                        isinstance(url, dict) and \n",
    "                        'expanded_url' in url and \n",
    "                        len(url['expanded_url']) > 0\n",
    "                    ):\n",
    "                        base_domain = extract_base_domain(url['expanded_url'])\n",
    "                        if base_domain not in exclude_domains:\n",
    "                            domains.append(base_domain)\n",
    "\n",
    "    print(Counter(domains).most_common(20))\n",
    "    print(f\"Cluster size: {df.shape[0]}\")\n",
    "    print(f\"Avg EC: {df['eigencentrality'].mean()}\")\n",
    "    print(f\"Max EC: {df.sort_values(by='eigencentrality', ascending=False).head(2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c5889f0-12a1-43a3-b260-ac14e4666adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('breitbart.com', 259), ('foxnews.com', 65), ('nypost.com', 32), ('dailycaller.com', 26), ('thefederalist.com', 24), ('washingtonexaminer.com', 23), ('dailymail.co.uk', 21), ('redstate.com', 15), ('justthenews.com', 14), ('townhall.com', 12), ('americanthinker.com', 12), ('thepostmillennial.com', 12), ('zerohedge.com', 10), ('pjmedia.com', 10), ('westernjournal.com', 7), ('theconservativetreehouse.com', 7), ('newsmax.com', 6), ('rumble.com', 6), ('hotair.com', 6), ('dailywire.com', 6)]\n",
      "Cluster size: 72\n",
      "Avg EC: 0.42782433333333336\n",
      "Max EC:                Id         Label  modularity_class  componentnumber  \\\n",
      "122  '4899465914'  '4899465914'                64                0   \n",
      "\n",
      "     eigencentrality  Size  \n",
      "122              1.0  10.0  \n"
     ]
    }
   ],
   "source": [
    "get_top_domains(en_clusters_64, 'en', en_data, en_exclude_domains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "683ff5b4-1774-4a1b-a545-15fb7aee3c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('foxnews.com', 138), ('foxbusiness.com', 20), ('nypost.com', 11), ('breitbart.com', 9), ('washingtonexaminer.com', 7), ('dailycaller.com', 7), ('redstate.com', 5), ('babylonbee.com', 5), ('msn.com', 4), ('theguardian.com', 4), ('newsbreak.com', 4), ('newsbreakapp.com', 3), ('dailymail.co.uk', 3), ('politico.com', 2), ('washingtontimes.com', 2), ('rumble.com', 2), ('pbs.org', 2), ('justthenews.com', 2), ('thefederalist.com', 2), ('dailywire.com', 2)]\n",
      "Cluster size: 40\n",
      "Avg EC: 0.168047925\n",
      "Max EC:               Id        Label  modularity_class  componentnumber  \\\n",
      "119  '343429091'  '343429091'                39                0   \n",
      "\n",
      "     eigencentrality      Size  \n",
      "119         0.604227  6.436669  \n"
     ]
    }
   ],
   "source": [
    "get_top_domains(en_clusters[en_clusters['modularity_class']==39], 'en', en_data, en_exclude_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31b434bc-7afb-4b10-94d7-fd47d094ebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rawstory.com', 164), ('newsweek.com', 29), ('mediaite.com', 27), ('palmerreport.com', 23), ('alternet.org', 21), ('crooksandliars.com', 19), ('msn.com', 14), ('politicususa.com', 13), ('thedailybeast.com', 11), ('substack.com', 9), ('thehill.com', 6), ('salon.com', 6), ('msnbc.com', 6), ('theguardian.com', 6), ('dailykos.com', 6), ('huffpost.com', 6), ('apnews.com', 5), ('axios.com', 5), ('washingtonpost.com', 4), ('newrepublic.com', 3)]\n",
      "Cluster size: 54\n",
      "Avg EC: 0.023622148148148146\n",
      "Max EC:              Id       Label  modularity_class  componentnumber  \\\n",
      "102  '20817529'  '20817529'                43                0   \n",
      "\n",
      "     eigencentrality      Size  \n",
      "102         0.070835  1.634285  \n"
     ]
    }
   ],
   "source": [
    "get_top_domains(en_clusters[en_clusters['modularity_class']==43], 'en', en_data, en_exclude_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e46e4d32-f4aa-4797-b01c-16fe61b10935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('washingtonpost.com', 49), ('theguardian.com', 26), ('msnbc.com', 24), ('thedailybeast.com', 15), ('thehill.com', 11), ('dailykos.com', 11), ('apnews.com', 10), ('twitter.com', 10), ('nbcnews.com', 8), ('newrepublic.com', 7), ('cnn.com', 6), ('wsj.com', 5), ('newsweek.com', 5), ('alternet.org', 5), ('nytimes.com', 5), ('lgbtqnation.com', 4), ('politico.com', 4), ('substack.com', 4), ('propublica.org', 4), ('bbc.com', 3)]\n",
      "Cluster size: 46\n",
      "Avg EC: 0.0028649565217391316\n",
      "Max EC:                         Id                  Label  modularity_class  \\\n",
      "209  '1431355664098603010'  '1431355664098603010'                18   \n",
      "171             '23847371'             '23847371'                18   \n",
      "\n",
      "     componentnumber  eigencentrality      Size  \n",
      "209                0         0.027825  1.247045  \n",
      "171                0         0.009219  1.079529  \n"
     ]
    }
   ],
   "source": [
    "get_top_domains(en_clusters[en_clusters['modularity_class']==18], 'en', en_data, en_exclude_domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c6c41d-4670-4f48-96a1-389052ce78c1",
   "metadata": {},
   "source": [
    "#### Spanish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b523cb63-f844-4139-b094-b3940e506aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_clusters = pd.read_csv(\"es_co_domain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d1884f5-1f77-438f-a770-688dc5386760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('clarin.com', 731), ('abc.es', 343), ('cnn.com', 292), ('euronews.com', 105), ('google.com', 69), ('enter.co', 62), ('noticiasuno.com', 39), ('elcomercio.com', 32), ('colombia.com', 28), ('las2orillas.co', 27), ('elnacional.com', 26), ('BBC.com', 8), ('eltiempo.com', 7), ('reforma.com', 4), ('elnacional.com.do', 4), ('elpais.com', 4), ('washingtonpost.com', 3), ('lanacion.com.ar', 3), ('nytimes.com', 2), ('elmundo.es', 2)]\n",
      "Cluster size: 141\n",
      "Avg EC: 0.8161753617021277\n",
      "Max EC:                         Id                  Label  modularity_class  \\\n",
      "567  '1609913670011858945'  '1609913670011858945'                28   \n",
      "607           '3206275589'           '3206275589'                28   \n",
      "\n",
      "     eigencentrality      Size  \n",
      "567         1.000000  9.000000  \n",
      "607         0.997883  8.987295  \n"
     ]
    }
   ],
   "source": [
    "get_top_domains(es_clusters[es_clusters['modularity_class']==28], 'es', es_data, es_exclude_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb349a77-5d79-4e8f-b602-8d98e34b188b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
