{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb2729c-b303-4b22-ad12-5713ff1b107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import ast\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de0114ff-44a3-48b0-890a-ca56ba83d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7723c716-6fb2-4f70-a242-6c55abe6f632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bowenyi/.local/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d55cff-abe8-47ba-87a0-b6e8f1455d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_data = pd.read_csv(\"en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421b595f-8afd-4856-b160-91e4b2d8afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_data = pd.read_csv(\"es.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6bbee9d-47dc-4b13-8e78-e621cb1f489b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>epoch</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>links</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>conversationId</th>\n",
       "      <th>mentionedUsers</th>\n",
       "      <th>id_str</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>statusesCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.800890e+18</td>\n",
       "      <td>@stayintham Mi amiga la que quiere ahorrar</td>\n",
       "      <td>es</td>\n",
       "      <td>1.718201e+09</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800879e+18</td>\n",
       "      <td>[{'id_str': '1197160866002718722', 'name': 'lu...</td>\n",
       "      <td>'966746102'</td>\n",
       "      <td>144</td>\n",
       "      <td>220</td>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                        text lang  \\\n",
       "0  1.800890e+18  @stayintham Mi amiga la que quiere ahorrar   es   \n",
       "\n",
       "          epoch hashtags links  replyCount  retweetCount  likeCount  \\\n",
       "0  1.718201e+09       []    []         1.0           0.0        0.0   \n",
       "\n",
       "   quoteCount  conversationId  \\\n",
       "0         0.0    1.800879e+18   \n",
       "\n",
       "                                      mentionedUsers       id_str  \\\n",
       "0  [{'id_str': '1197160866002718722', 'name': 'lu...  '966746102'   \n",
       "\n",
       "   followersCount  friendsCount  statusesCount  \n",
       "0             144           220           3081  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff609fe3-a700-4653-b5cf-cb43246c3b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'lang', 'epoch', 'hashtags', 'links', 'replyCount',\n",
       "       'retweetCount', 'likeCount', 'quoteCount', 'conversationId',\n",
       "       'mentionedUsers', 'id_str', 'followersCount', 'friendsCount',\n",
       "       'statusesCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e191c6-a1a8-4a2e-bbf4-5102edc02587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_format(field):\n",
    "    return ast.literal_eval(field)\n",
    "\n",
    "en_data['hashtags'] = en_data['hashtags'].apply(convert_format)\n",
    "en_data['links'] = en_data['links'].apply(convert_format)\n",
    "en_data['mentionedUsers'] = en_data['mentionedUsers'].apply(convert_format)\n",
    "\n",
    "es_data['hashtags'] = es_data['hashtags'].apply(convert_format)\n",
    "es_data['links'] = es_data['links'].apply(convert_format)\n",
    "es_data['mentionedUsers'] = es_data['mentionedUsers'].apply(convert_format)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dfa782-9348-4ad0-9d49-f267525b3bab",
   "metadata": {},
   "source": [
    "### 1. Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a4f53-238b-4792-a962-ea4223732be6",
   "metadata": {},
   "source": [
    "#### 1.1 Text similarity network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efe97321-bc42-40d3-82d8-de45ad9ce237",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\").to(device)\n",
    "\n",
    "def construct_text_similarity_network(dataframe):\n",
    "    user_text_map = defaultdict(list)\n",
    "    for _, row in dataframe.iterrows():\n",
    "        user = row['id_str']\n",
    "        text = row['text']\n",
    "        if isinstance(text, str):\n",
    "            user_text_map[user].append(text)\n",
    "\n",
    "    user_embeddings = {}\n",
    "    for user, texts in user_text_map.items():\n",
    "        embeddings = model.encode(texts, device=device)\n",
    "        user_embeddings[user] = np.mean(embeddings, axis=0)\n",
    "\n",
    "    user_ids = list(user_embeddings.keys())\n",
    "    user_vectors = np.array(list(user_embeddings.values()))\n",
    "    similarity_matrix = cosine_similarity(user_vectors)\n",
    "\n",
    "    # Build user-user graph\n",
    "    G = nx.Graph()\n",
    "    for i, user1 in enumerate(user_ids):\n",
    "        for j, user2 in enumerate(user_ids):\n",
    "            if i != j and similarity_matrix[i, j] > 0.7:\n",
    "                G.add_edge(user1, user2, weight=similarity_matrix[i, j])\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def9bc5-73e5-450d-98e0-ac40a2cce8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_text_graph = construct_text_similarity_network(en_data)\n",
    "es_text_graph = construct_text_similarity_network(es_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e54b7-9cff-493a-9c3f-3d6bbc6271ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(en_text_graph, open('en_text_graph.gpickle', 'wb'))\n",
    "pickle.dump(es_text_graph, open('es_text_graph.gpickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab90e20-e80d-48e6-b44f-5e45150f7522",
   "metadata": {},
   "source": [
    "#### 1.2 co-Hashtags network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e555b89-0f4d-44c8-b7c7-1b246b7e2224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8cf7afc-3033-4ade-83b3-14b302dbd48e",
   "metadata": {},
   "source": [
    "#### 1.3 Co-URL network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6625a008-13d2-4100-9518-1f4ce014442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_co_url_network(dataframe):\n",
    "    # 1: Extract user-URL mappings\n",
    "    user_url_map = defaultdict(list)\n",
    "    for _, row in dataframe.iterrows():\n",
    "        user = row['id_str']\n",
    "        links = row['links']\n",
    "        if isinstance(links, list):\n",
    "            for link in links:\n",
    "                expanded_url = link.get('expanded_url')\n",
    "                if expanded_url:\n",
    "                    user_url_map[user].append(expanded_url)\n",
    "\n",
    "    # 2: Create user-URL matrix (rows representing users, cols representing URLs)\n",
    "    users = list(user_url_map.keys())\n",
    "    urls = list({url for url_list in user_url_map.values() for url in url_list})\n",
    "    user_url_matrix = np.zeros((len(users), len(urls)))\n",
    "\n",
    "    for i, user in enumerate(users):\n",
    "        for url in user_url_map[user]:\n",
    "            if url in urls:\n",
    "                user_url_matrix[i, urls.index(url)] = 1\n",
    "\n",
    "    # 3: Compute cosine similarity between users \n",
    "    similarity_matrix = cosine_similarity(user_url_matrix)  # Calculate the cosine sim between rows (users)\n",
    " \n",
    "    # 4: Build user-user graph\n",
    "    G = nx.Graph()\n",
    "    for i, user1 in enumerate(users):\n",
    "        for j, user2 in enumerate(users):\n",
    "            if i != j and similarity_matrix[i, j] > 0.7:\n",
    "                G.add_edge(user1, user2, weight=similarity_matrix[i, j])\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b3162e-1d05-481d-ba3b-c9adc8b9611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Co-URL networks for English and Spanish data\n",
    "en_co_url_graph = construct_co_url_network(en_data)\n",
    "es_co_url_graph = construct_co_url_network(es_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7e34b40-4484-409c-9a51-d9e5309fec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save graphs for further use\n",
    "pickle.dump(en_co_url_graph, open('en_co_url_graph.pickle', 'wb'))\n",
    "pickle.dump(es_co_url_graph, open('es_co_url_graph.pickle', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c75754-45c3-4209-a55b-8aeaff2c07a8",
   "metadata": {},
   "source": [
    "#### 1.4 Network Fusion\n",
    "- Might consider temporary indicators (epoch)\n",
    "- Might also add linguistic features like formality and toxicity, if time allows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9822f0d-7a52-4cee-93e2-95622f37450f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
